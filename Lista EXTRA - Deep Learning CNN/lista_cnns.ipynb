{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f94ddb7",
   "metadata": {},
   "source": [
    "## CONFIGURAÇÕES GLOBAIS E CAMINHOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ffdefa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "# CONFIGURAÇÕES GLOBAIS E CAMINHOS\n",
    "\n",
    "# Caminho onde estão as pastas originais do dataset (PetImages)\n",
    "DIRETORIO_ORIGINAL = './PetImages'\n",
    "\n",
    "# Caminho onde será criada a base dividida (treino/teste)\n",
    "BASE_DIR = './dataset_organizado' \n",
    "\n",
    "# Parâmetros\n",
    "TAMANHO_IMAGEM = (150, 150)\n",
    "BATCH_SIZE = 64 # Depois de testes, foi o melhor valor que encontrei para um tempo razoável de treino no meu computador\n",
    "SPLIT_SIZE = 0.8  # 80% para Treino 20% para Teste\n",
    "\n",
    "# Hiperparâmetros Ajustados\n",
    "# Taxa de aprendizado reduzida para estabilizar o treinamento, conforme análise gráfica\n",
    "LEARNING_RATE = 0.001  # Padrão do otimizador Adam\n",
    "EPOCHS = 30 \n",
    "PATIENCE = 5 # Limite de épocas antes da parada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11192a9",
   "metadata": {},
   "source": [
    "## Organização e separação das imagens do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87082b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando organização e separação dos dados (80/20)...\n",
      "  - 12498 imagens de Cat processadas e separadas.\n",
      "  - 12498 imagens de Dog processadas e separadas.\n",
      "Organização e separação concluídas.\n"
     ]
    }
   ],
   "source": [
    "# Divisão do treino/teste sobre a pasta PetImages\n",
    "def criar_e_organizar_pastas(diretorio_original, base_dir, split_size):\n",
    "    \"\"\"Cria a estrutura de pastas de treino/teste e move arquivos.\"\"\"\n",
    "    print(\"Iniciando organização e separação dos dados (80/20)...\")\n",
    "\n",
    "    CAT_SOURCE_DIR = os.path.join(diretorio_original, 'Cat')\n",
    "    DOG_SOURCE_DIR = os.path.join(diretorio_original, 'Dog')\n",
    "\n",
    "    if not os.path.isdir(CAT_SOURCE_DIR) or not os.path.isdir(DOG_SOURCE_DIR):\n",
    "        print(\"\\nERRO: Diretórios 'Cat' ou 'Dog' não encontrados. Verifique a base de dados.\")\n",
    "        return False\n",
    "\n",
    "    # Limpeza e Criação de Pastas\n",
    "    if os.path.exists(base_dir):\n",
    "        shutil.rmtree(base_dir)\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "    for folder in ['treino', 'teste']:\n",
    "        os.makedirs(os.path.join(base_dir, folder, 'cats'))\n",
    "        os.makedirs(os.path.join(base_dir, folder, 'dogs'))\n",
    "\n",
    "    # Separa as imagens de treino/teste\n",
    "    def separar_arquivos(source_dir, dest_train_dir, dest_test_dir, split):\n",
    "        \"\"\"Move e separa os arquivos em treino e teste.\"\"\"\n",
    "        files = [f for f in os.listdir(source_dir) if f.lower().endswith(('jpg', 'jpeg', 'png'))]\n",
    "        # Remove arquivos corrompidos comuns na base do Kaggle (ex: 666.jpg ou 11702.jpg)\n",
    "        files = [f for f in files if f not in ('666.jpg', '11702.jpg')]\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        split_point = int(len(files) * split)\n",
    "\n",
    "        # Copia para Treino e Teste\n",
    "        for file in files[:split_point]:\n",
    "            shutil.copyfile(os.path.join(source_dir, file), os.path.join(dest_train_dir, file))\n",
    "        for file in files[split_point:]:\n",
    "            shutil.copyfile(os.path.join(source_dir, file), os.path.join(dest_test_dir, file))\n",
    "        \n",
    "        print(f\"  - {len(files)} imagens de {os.path.basename(source_dir)} processadas e separadas.\")\n",
    "\n",
    "    # Separar de acordo com a classe\n",
    "    separar_arquivos(CAT_SOURCE_DIR, \n",
    "                     os.path.join(base_dir, 'treino', 'cats'), \n",
    "                     os.path.join(base_dir, 'teste', 'cats'), \n",
    "                     split_size)\n",
    "\n",
    "    # Separar de acordo com a classe\n",
    "    separar_arquivos(DOG_SOURCE_DIR, \n",
    "                     os.path.join(base_dir, 'treino', 'dogs'), \n",
    "                     os.path.join(base_dir, 'teste', 'dogs'), \n",
    "                     split_size)\n",
    "\n",
    "    print(\"Organização e separação concluídas.\")\n",
    "    return True\n",
    "\n",
    "if not criar_e_organizar_pastas(DIRETORIO_ORIGINAL, BASE_DIR, SPLIT_SIZE):\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437a91b",
   "metadata": {},
   "source": [
    "## PRÉ-PROCESSAMENTO E DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "447a76bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando pré-processamento...\n",
      "\n",
      "Carregando dados de TREINO...\n",
      "Found 19996 images belonging to 2 classes.\n",
      "Carregando dados de TESTE...\n",
      "Found 5000 images belonging to 2 classes.\n",
      "\n",
      "Classes encontradas: {'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIniciando pré-processamento...\")\n",
    "\n",
    "# Gerador de TREINO (Com Normalização e Aumento de Dados)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,             # Normalização de pixels (0-1)\n",
    "    rotation_range=40,          # Rotação\n",
    "    width_shift_range=0.2,      # Deslocamento Horizontal\n",
    "    height_shift_range=0.2,     # Deslocamento Vertical\n",
    "    shear_range=0.2,            # Cisalhamento\n",
    "    zoom_range=0.2,             # Zoom\n",
    "    horizontal_flip=True,       # Inversão Horizontal\n",
    "    fill_mode='nearest'         # Preenchimento\n",
    ")\n",
    "\n",
    "# Gerador de TESTE (Apenas Normalização)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Carregamento dos dados\n",
    "print(\"\\nCarregando dados de TREINO...\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(BASE_DIR, 'treino'),\n",
    "    target_size=TAMANHO_IMAGEM,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    ")\n",
    "\n",
    "print(\"Carregando dados de TESTE...\")\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(BASE_DIR, 'teste'),\n",
    "    target_size=TAMANHO_IMAGEM,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    ")\n",
    "\n",
    "# Mostrar classes identificadas\n",
    "print(f\"\\nClasses encontradas: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971bf65",
   "metadata": {},
   "source": [
    "## CONSTRUÇÃO E TREINAMENTO DA CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConstruindo o modelo CNN...\")\n",
    "\n",
    "# Arquitetura simples: Conv -> Pool -> Flatten -> Dense -> Output\n",
    "model = Sequential([\n",
    "    # Bloco 1\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Bloco 2\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Bloco 3\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Camadas de Classificação\n",
    "    Flatten(),\n",
    "    Dropout(0.3),# Regularização para evitar overfitting\n",
    "    Dense(256, activation='relu'), # Era 512 -> 256 para melhorar a performance\n",
    "    \n",
    "    # Camada de Saída (Sigmoid para classificação binária)\n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "# Compilação do modelo com o LEARNING_RATE de 0.001\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), # Usa o otimizador Adam com taxa de aprendizado definida\n",
    "              loss='binary_crossentropy', # Função de perda adequada para classificação binária\n",
    "              metrics=['accuracy']) # Mais adequada para avaliar o desempenho do modelo\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Definição do Early Stopping (parada antecipada)\n",
    "early_stop = EarlyStopping(monitor='val_loss', # Monitora a perda de validação\n",
    "                           patience=PATIENCE,   # Número de épocas sem melhoria para parar\n",
    "                           restore_best_weights=True) # Volta aos pesos da melhor época\n",
    "\n",
    "print(\"\\nIniciando treinamento...\")\n",
    "\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stop], # parada antecipada\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a29d6",
   "metadata": {},
   "source": [
    "## PLOTAGENS DOS GRÁFICOS DE DESEMPENHO (acurácia e perda por época)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Acurácia de Treino')\n",
    "plt.plot(epochs_range, val_acc, label='Acurácia de Validação')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Acurácia de Treino e Validação')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Perda de Treino')\n",
    "plt.plot(epochs_range, val_loss, label='Perda de Validação')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Perda (Loss) de Treino e Validação')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1804ecbf",
   "metadata": {},
   "source": [
    "## AVALIAÇÃO E TESTES COM O MODELO (PRECISÃO, RECALL, F1-SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e797906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Avaliação de Desempenho no Conjunto de Teste ---\")\n",
    "\n",
    "# Gerador de avaliação com shuffle=False para garantir que a ordem dos labels seja correta\n",
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "    os.path.join(BASE_DIR, 'teste'),\n",
    "    target_size=TAMANHO_IMAGEM,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 1. Fazer previsões\n",
    "# steps garante que o modelo passe por TODAS as imagens do teste.\n",
    "Y_pred = model.predict(eval_generator, steps=len(eval_generator)) \n",
    "\n",
    "# 2. Converter probabilidades para classes (0 ou 1)\n",
    "y_pred_classes = np.where(Y_pred > 0.5, 1, 0) \n",
    "\n",
    "# 3. Obter classes verdadeiras (elas estarão na ordem correta devido ao shuffle=False)\n",
    "y_true = eval_generator.classes\n",
    "\n",
    "# 4. Gerar Relatório de Classificação e Matriz de Confusão\n",
    "target_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\nRelatório de Classificação (Precision, Recall, F1-Score):\")\n",
    "# Target_names para garantir a visualização correta das classes 0 e 1\n",
    "print(classification_report(y_true, y_pred_classes, target_names=target_names))\n",
    "\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34aa87",
   "metadata": {},
   "source": [
    "## Teste com Imagens Externas (pasta \"./teste_externos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c08133",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOVO_TESTE_DIR = './testes_externos' \n",
    "\n",
    "def predizer_nova_imagem(img_path, model, target_size, class_indices):\n",
    "    \"\"\"\n",
    "    Função auxiliar para carregar, pré-processar (redimensionar e normalizar) \n",
    "    e realizar a predição de uma ÚNICA imagem externa, exibindo o resultado e a confiança.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Carregamento e Redimensionamento da Imagem\n",
    "        img = image.load_img(img_path, target_size=target_size)\n",
    "        img_array = image.img_to_array(img)\n",
    "        # Adiciona uma nova dimensão (batch_size=1) para compatibilidade com o modelo\n",
    "        img_array = np.expand_dims(img_array, axis=0) \n",
    "        # Normalização (0-1)\n",
    "        img_array /= 255.0\n",
    "\n",
    "        # Previsão da probabilidade\n",
    "        prediction = model.predict(img_array)\n",
    "        \n",
    "        # Inverte o dicionário de classes para mapear 0 ou 1 para 'cats' ou 'dogs'\n",
    "        classes = {v: k for k, v in class_indices.items()}\n",
    "        \n",
    "        # Lógica de Classificação Binária (acima de 0.5 é 'dogs', abaixo é 'cats')\n",
    "        if prediction[0] > 0.5:\n",
    "            resultado = classes[1] # dogs (1)\n",
    "            probabilidade = prediction[0][0]\n",
    "        else:\n",
    "            resultado = classes[0] # cats (0)\n",
    "            # Se for 'cats', a confiança é 1 - Probabilidade do cão\n",
    "            probabilidade = 1.0 - prediction[0][0] \n",
    "\n",
    "        print(f\"Arquivo: {os.path.basename(img_path)}\")\n",
    "        print(f\"   Previsão: {resultado} (Probabilidade: {probabilidade:.4f})\")\n",
    "        \n",
    "        # Visualização da Imagem e Resultado\n",
    "        plt.figure()\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Previsão: {resultado} ({probabilidade*100:.2f}%)\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Não foi possível processar a imagem {img_path}. Erro: {e}\")\n",
    "        \n",
    "print(\"\\n--- 3.2 Teste com Novas Imagens ---\")\n",
    "\n",
    "if os.path.isdir(NOVO_TESTE_DIR):\n",
    "    # Lógica para iterar por todas as imagens suportadas na pasta 'testes_externos'\n",
    "    new_images_to_test = [os.path.join(NOVO_TESTE_DIR, f) for f in os.listdir(NOVO_TESTE_DIR) \n",
    "                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if new_images_to_test:\n",
    "        for img_path in new_images_to_test:\n",
    "            predizer_nova_imagem(img_path, model, TAMANHO_IMAGEM, train_generator.class_indices)\n",
    "    else:\n",
    "        print(f\"Nenhuma imagem encontrada em {NOVO_TESTE_DIR}. Adicione as imagens para o teste final.\")\n",
    "else:\n",
    "    print(f\"Pasta de teste '{NOVO_TESTE_DIR}' não encontrada. Crie a pasta e adicione imagens externas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
